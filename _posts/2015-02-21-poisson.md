---
layout: post
title: The Poisson Process and its Cousins
---

A colleague who was learning probability theory recently pointed out to me that
he could easily get the uniform distribution out a Poisson process with a rather
simple process. In this post, I am recording for posterity his process and
this fact that I never really thought about as well as a simple proof that
holds for any real-valued stochastic process with stationary and independent
increments.

## What is a Poisson Process?

First, recall that a *counting process* is a stochastic process \\(\\{ N(t) :
t \geq 0 \\}\\) subject to \\(N(t) \\in \\mathbb{Z}\\) for all \\(t\\) and
\\(N(s) \leq N(t)\\) whenever \\(s \leq t\\). Note that without loss of generality,
we can assume that \\(N(0) = 0\\) and so \\(N(t)\\) is nonnegative for all time.

Then note that since \\(\\mathbb{Z})\\) is countable, that in any particular
realization \\(n(t)\\) of \\(N(t)\\), the total number of *jump points* \\(p\\)
where \\[ \\lim\_\{t \to p^-\} n(t) \ne \\lim\_\{t \to p^+\} n(t)\\] must be
countable. In particular, in any definition of a counting process, the total
number transition points must be (almost surely) countable.

From here on, denote by \\(p\_1, p\_2, \ldots\\) the random variables which are
jump points of the process, and by \\(w\_i = p\_i - p\_\{i-1\}\\) the *waiting
times* of the process, where by convention \\(p\_0 = 0\\).

Note also that for any counting process (and really any stochastic process) we
may define the *increments* \\(I(s, t)\\) of the process as \\(N(t) - N(s)\\).

So we come to the definition of a Poisson process. Here, we make a few further
assumptions on \\(N(t)\\). First, we assume that \\(N(t)\\) has *independent
increments*, i.e., that if \\(a \leq b < c \leq d\\) then \\(I(a, b)\\) and
\\(I(c, d)\\) are independent.

Secondly, we assume that \\(N(t)\\) has *stationary increments*, i.e., that
for each \\(\ell \geq 0\\) there is a random variable \\(X_\ell\\) such that
for any \\(a \geq 0\\) we have \\(I(a, a + \ell) \sim X_\ell\\). That is, the
distribution of the increment only depends on the length of the time interval
of the increment.

Note that these two assumptions together imply that the waiting times are
independently, identically distributed random variables.

Third, we assume that each increment \\(I(a, b)\\) is distributed as a Poisson
random variable with a rate parameter \\(\mu = \lambda (b - a)\\) for some
\\(\lambda > 0\\).  Recall that a Poisson random variable is a nonnegative
integer valued random variable whose probability mass function \\(Pr(X = k) =
\mu^k \exp(-\mu) /k!\\).

As is usually pointed out, his then implies that the waiting times are
exponentially distributed with rate parameter \\(\lambda\\). To see this, note
that since the waiting times are i.i.d., it suffices to consider the first
waiting time. But \\[ Pr(w_1 \leq t) = Pr(I(0, t) \geq 1) = 1 - \exp(-\lambda
t), \\] which is the cdf of the exponential distribution with rate
\\(\lambda\\).

## The uniform distribution from a "random" timestamp

So what about that uniform distribution? Let \\(N(t)\\) be a Poisson process
and let \\(p_1, p_2, \ldots\\) be the event timestamps (also called the jump
points).  Let \\(P = \{ p_i : p_i < T \}\\). Then choose uniformly at random
an element of \\(p)\\). If \\(P = \varnothing\\), simply denote \\(p =
\varnothing\\).  What is the distribution of \\(X\\)? My colleague had the
intuition that this should be uniform on \\((0, T)\\) (except for the delta at
\\(\varnothing\\)) because of the memorylessness of the Poisson process. But
that is not quite right. We actually only need that the process has stationary
and independent increments!

In particular, note that the uniform distribution \\(U\\) on \\((0, T)\\) is
characterized by the fact that for each \\(\ell < T\\) there is a constant
\\(C(\ell, T)\\) such that for each \\(0 < a < T - \ell\\), \\(Pr(U \in (a, a +
\ell)) = C(\ell, T)\\).

On the other hand, the probability that \\(X \in (a, b)\\) is the number of
elements of \\(P\\) in \\((a, b)\\) divided by the total number of elements
of \\(P\\) given that \\(P\\) has at least one element. But that is simply
\\((I(a, b) / I(0, T)) | I(0, T) > 0\\).

Now by stationary and independent increments and the definition of increments,
we may write this ratio as \\((P(\ell) / (P(T - \ell) + P(\ell))) | I(0, T) >
0\\) where \\(\ell = b - a\\) and \\(P(\ell)\\) is a Poisson random variable
with rate \\(\lambda \ell\\). Thus, whatever follows in computing the actual
probability that \\(X \in (a, b)\\), we have removed the dependence on
\\(a\\) and have reduced it to a depedence only on \\(\ell\\) and \\(T\\).
Thus, whatever number is yielded, it depends only on \\(\ell\\) and \\(T\\)
and so \\(X | X \ne \varnothing\\) must have a uniform distribution.
